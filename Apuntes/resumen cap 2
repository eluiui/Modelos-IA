CAPÍTULO 2 – Agentes Inteligentes
Idea central del capítulo

El capítulo explica qué es un agente inteligente, cómo interactúa con su entorno, qué significa que un agente sea racional y por qué la autonomía y el aprendizaje son esenciales. Todo el capítulo se centra en el agente racional como ideal de diseño.

2.1 Agentes y Entornos

Definición de agente:
Un agente es cualquier entidad que:

Percibe su entorno mediante sensores.

Actúa sobre su entorno mediante actuadores.

Ejemplos: humanos, robots, programas de software.

Percepto: Información recibida por el agente en un momento determinado.
Secuencia de perceptos: Historial completo de percepciones.

Función del agente:
Relaciona: Secuencia de perceptos → Acción

Programa del agente:
Implementa la función del agente en software.

Ejemplo: Mundo de la aspiradora

Percibe suciedad en dos cuartos (A y B).

Acciones: aspirar o moverse.

Estrategia simple:

Si hay suciedad → aspirar

Si no → moverse

2.2 Buen comportamiento: la racionalidad

Agente racional: aquel que elige la acción que maximiza su rendimiento esperado según la información disponible.

2.2.1 Medida de rendimiento

Evalúa consecuencias de acciones en el entorno.

Debe reflejar correctamente lo que se quiere lograr (ej. estado del suelo limpio, no cantidad de veces aspiradas).

2.2.2 Factores de un agente racional

Medida de rendimiento

Conocimiento previo del entorno

Acciones disponibles

Secuencia de perceptos

2.2.3 Omnisciencia, aprendizaje y autonomía

Racionalidad ≠ omnisciencia

El agente actúa con la información disponible

Aprender es esencial para mejorar rendimiento y adaptarse

Autonomía: capacidad de aprender y adaptarse más allá del comportamiento programado

2.3 La naturaleza de los entornos
2.3.1 Especificación del entorno: PEAS

Performance: criterios de éxito

Environment: entorno de actuación

Actuators: formas de actuar

Sensors: formas de percibir

Ejemplo: taxi automatizado

Performance: viaje seguro, rápido, cómodo, legal

Entorno: carreteras, tráfico, peatones, clima

Actuadores: volante, freno, acelerador, señales

Sensores: cámaras, radar, GPS, micrófonos

2.3.2 Propiedades de los entornos

Observabilidad: totalmente observable, parcialmente observable

Agentes: uno o multiagente (competitivo o cooperativo)

Determinismo: determinístico, no determinístico, estocástico

Secuencialidad: episódico o secuencial

Dinámica: estático, dinámico, semidinámico

Tipo de datos: discreto o continuo

Conocimiento: conocido o desconocido por el agente

Entornos más complejos: parcialmente observable + multiagente + estocástico + secuencial + dinámico + continuo + desconocido

2.4 La estructura de los agentes
Arquitectura vs. Programa

Arquitectura: hardware con sensores y actuadores

Programa: convierte percepciones en acciones

Agente = Arquitectura + Programa

Tipos de programas/agentes

Agentes basados en tablas: impracticables por tamaño de memoria

Agentes reflejos simples: actúan según percepto actual; rápidos pero limitados

Agentes reflejos con modelo: mantienen estado interno; manejan entornos parcialmente observables

Agentes basados en objetivos: planifican para lograr metas explícitas; consideran futuro

Agentes basados en utilidad: maximizan función de utilidad; manejan conflictos y probabilidades

Agentes que aprenden: mejoran con experiencia; usan retroalimentación y exploración

Representación del mundo

Atómica: estado como un todo

Factorizada: conjunto de variables/atributos

Estructurada: objetos y relaciones

Resumen de capacidades por tipo de agente:

Tipo de agente	Memoria	Modelo	Metas	Utilidad	Aprende
Reflejo simple	❌	❌	❌	❌	❌
Con modelo	✅	✅	❌	❌	❌
Basado en metas	✅	✅	✅	❌	❌
Basado en utilidad	✅	✅	✅	✅	❌
Que aprende	✅	✅	✅	✅	✅
1. ¿Qué es un agente inteligente? Da ejemplos.
Un agente inteligente es cualquier entidad que percibe su entorno mediante sensores y actúa sobre él mediante actuadores, con el objetivo de maximizar su desempeño según ciertos criterios.
Ejemplos:

Humano: ojos, oídos (sensores); manos, piernas (actuadores).

Robot aspiradora: sensores de suciedad, motores para moverse y limpiar.

Programa de software: entradas de datos (sensor), salidas en pantalla (actuador).

2. Diferencia entre percepto y secuencia de perceptos.

Percepto: Información recibida por el agente en un instante.

Secuencia de perceptos: Historial completo de todas las percepciones hasta el momento, que puede influir en la acción del agente.

3. ¿Qué elementos definen un agente racional?
Un agente racional depende de cuatro factores:

Medida de rendimiento (criterio objetivo de éxito).

Conocimiento previo del entorno.

Acciones disponibles.

Secuencia de perceptos.

Un agente racional elige la acción que maximiza su rendimiento esperado con la información disponible.

4. Explica el modelo PEAS y da un ejemplo.
PEAS describe el entorno de la tarea de un agente:

P (Performance): cómo medir el éxito del agente.

E (Environment): entorno donde actúa.

A (Actuators): cómo actúa el agente.

S (Sensors): cómo percibe el entorno.

Ejemplo: Taxi autónomo

Performance: viaje seguro, rápido y cómodo.

Entorno: carreteras, tráfico, peatones.

Actuadores: volante, freno, acelerador, bocina.

Sensores: cámaras, radar, GPS, micrófonos.

5. Clasifica los entornos según: observabilidad, determinismo y número de agentes.

Observabilidad: totalmente observable (ajedrez), parcialmente observable (póker), no observable (agente que no recibe información).

Determinismo: determinístico (ajedrez), no determinístico/estocástico (conducir, póker).

Número de agentes: un agente (crucigrama), multiagente (tráfico, ajedrez).

6. Diferencia entre agente reflejo simple y agente con modelo.

Reflejo simple: actúa únicamente según el percepto actual, usando reglas “Si X → Y”. No tiene memoria ni conocimiento del estado del mundo.

Con modelo: mantiene un estado interno que representa el mundo, usando un modelo de transición y de sensores, lo que le permite actuar correctamente en entornos parcialmente observables.

7. ¿Qué ventajas tienen los agentes basados en metas frente a los reflejos?

Consideran no solo el estado actual sino también objetivos futuros.

Pueden planificar acciones para alcanzar metas específicas.

Son más flexibles y adaptables a cambios en el entorno.

Separan conocimiento de acción, permitiendo decisiones más inteligentes.

8. ¿Qué es un agente basado en utilidad y por qué es más realista?
Un agente basado en utilidad no solo busca cumplir un objetivo, sino maximizar una función de utilidad que evalúa qué tan bueno es un estado y permite comparar distintos resultados.
Por qué es más realista:

Puede manejar conflictos (rapidez vs seguridad).

Considera incertidumbre y consecuencias probabilísticas.

Evalúa alternativas según su valor esperado, no solo si cumple la meta.

9. Explica cómo funciona un agente que aprende y sus componentes.
Un agente que aprende mejora su rendimiento con la experiencia mediante retroalimentación del entorno. Componentes:

Elemento de desempeño: decide las acciones.

Elemento de aprendizaje: ajusta el comportamiento según la experiencia.

Generador de problemas: propone exploración y nuevas acciones.

Elemento crítico de retroalimentación: evalúa resultados y recompensas/castigos.

10. Da ejemplos de representación atómica, factorizada y estructurada del mundo.

Atómica: estado visto como un todo sin partes (ej. posición del agente en un tablero de ajedrez).

Factorizada: estado como conjunto de variables (ej. gasolina, velocidad, clima de un vehículo).

Estructurada: estado como objetos y relaciones (ej. “Un camión bloquea a una vaca en el camino”).
